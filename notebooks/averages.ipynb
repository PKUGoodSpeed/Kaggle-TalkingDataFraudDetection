{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['logistic', 'lightGBM_3', 'lightGBM_0', 'randomFRST', 'randomFRST_2', 'lightGBM_2', 'lightGBM_1']\n"
     ]
    }
   ],
   "source": [
    "models = os.listdir('../output')\n",
    "print models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000001\n",
      "12471\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../output/{0}/fold_1/oof_pred.csv'.format(models[0]))\n",
    "target = df.is_attributed.values\n",
    "n = len(df)\n",
    "print n\n",
    "print list(target).count(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18790469\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../output/{0}/fold_1/test_pred.csv'.format(models[0]))\n",
    "ids = df.click_id.tolist()\n",
    "n_test = len(df)\n",
    "print n_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simple average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the ave of logistic\n",
      "1 0.9124174276 2 0.91249590902 3 0.911643691471 4 0.912530471636 5 0.911769611401 6 0.912087015757 7 0.911735940159 8 0.912116817579 9 0.911814780086 \n",
      " SCORE=0.912809181445\n",
      "Checking the ave of lightGBM_3\n",
      "1 0.975408758338 2 0.975515261339 3 0.975578902017 4 0.975436421283 5 0.975315179454 6 0.975047248939 7 0.975409852503 8 0.975364415994 9 0.974974347694 \n",
      " SCORE=0.976315623129\n",
      "Checking the ave of lightGBM_0\n",
      "1 0.974458964204 2 0.974579614774 3 0.974298369631 4 0.974639027306 5 0.974355254007 6 0.974252339806 7 0.974368777768 8 0.974533317012 9 0.97395381743 \n",
      " SCORE=0.975372260552\n",
      "Checking the ave of randomFRST\n",
      "1 0.968584547777 2 0.968613800856 3 0.967582925121 4 0.967970539446 5 0.967527060014 6 0.967907333169 7 0.968450162633 8 0.968043676641 9 0.96746591914 \n",
      " SCORE=0.971250412087\n",
      "Checking the ave of randomFRST_2\n",
      "1 0.96754824252 2 0.966985202479 3 0.967075828034 4 0.966459657932 5 0.967126319713 6 0.967194781781 7 0.967367484734 8 0.968114272328 9 0.966431213518 \n",
      " SCORE=0.972357143786\n",
      "Checking the ave of lightGBM_2\n",
      "1 0.975135394554 2 0.974951412095 3 0.974972015521 4 0.975054755777 5 0.975092386386 6 0.975171481588 7 0.975018919983 8 0.975187164684 9 0.97495807379 \n",
      " SCORE=0.976459945229\n",
      "Checking the ave of lightGBM_1\n",
      "1 0.974650009511 2 0.974606182413 3 0.974626104169 4 0.974870854694 5 0.974478021773 6 0.974722168362 7 0.975030597105 8 0.974435153863 9 0.974521888445 \n",
      " SCORE=0.975651944058\n"
     ]
    }
   ],
   "source": [
    "output_dir = '../simple_ave'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "for m in models:\n",
    "    print \"Checking the ave of \" + m\n",
    "    ans = np.zeros(n)\n",
    "    testp = np.zeros(n_test)\n",
    "    for i in range(1, 10):\n",
    "        print i,\n",
    "        df = pd.read_csv('../output/{0}/fold_{1}/oof_pred.csv'.format(m, i))\n",
    "        tmp = np.array(df.pred.tolist())\n",
    "        print roc_auc_score(target, tmp),\n",
    "        ans += 1./9. * tmp\n",
    "        df = pd.read_csv('../output/{0}/fold_{1}/test_pred.csv'.format(m, i))\n",
    "        testp += 1./9. * np.array(df.pred.tolist())\n",
    "    score = roc_auc_score(target, ans)\n",
    "    print \"\\n SCORE=\" + str(score)\n",
    "    oof_df = pd.DataFrame({\n",
    "        'is_attributed': list(target),\n",
    "        'pred': list(ans)\n",
    "    })\n",
    "    oof_df = oof_df[['is_attributed', 'pred']]\n",
    "    oof_df.to_csv(output_dir + '/' + m + '_oof_{SCORE}.csv'.format(SCORE=str(score)), index=False)\n",
    "    test_df = pd.DataFrame({\n",
    "        'click_id': ids,\n",
    "        'is_attributed': testp\n",
    "    })\n",
    "    test_df['click_id'] = test_df['click_id'].astype(int)\n",
    "    test_df = test_df[['click_id', 'is_attributed']]\n",
    "    test_df.to_csv(output_dir + '/' + m + '_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delta = 1E-10\n",
    "def sigmoid(x):\n",
    "    return 1. / (np.exp(-x)+1.)\n",
    "def upper(x):\n",
    "    return min(x, 1.-delta)\n",
    "def lower(x):\n",
    "    return max(x, delta)\n",
    "def rev(x):\n",
    "    return -np.log(1./x - 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000001\n",
      "Checking the ave of logistic\n",
      "1 0.9124174276 2 0.91249590902 3 0.911643691471 4 0.912530471636 5 0.911769611401 6 0.912087015757 7 0.911735940159 8 0.912116817579 9 0.911814780086 \n",
      " SCORE=0.912763298011\n",
      "Checking the ave of lightGBM_3\n",
      "1 0.975408758338 2 0.975515261339 3 0.975578902017 4 0.975436421283 5 0.975315179454 6 0.975047248939 7 0.975409852503 8 0.975364415994 9 0.974974347694 \n",
      " SCORE=0.976264602773\n",
      "Checking the ave of lightGBM_0\n",
      "1 0.974458964204 2 0.974579614774 3 0.974298369631 4 0.974639027306 5 0.974355254007 6 0.974252339806 7 0.974368777768 8 0.974533317012 9 0.97395381743 \n",
      " SCORE=0.975416070448\n",
      "Checking the ave of randomFRST\n",
      "1 0.968584547777 2 0.968613800856 3 0.967582925121 4 0.967970539446 5 0.967527060014 6 0.967907333169 7 0.968450162633 8 0.968043676641 9 0.96746591914 \n",
      " SCORE=0.970591719946\n",
      "Checking the ave of randomFRST_2\n",
      "1 0.96754824252 2 0.966985202479 3 0.967075828034 4 0.966459657932 5 0.967126319713 6 0.967194781781 7 0.967367484734 8 0.968114272328 9 0.966431213518 \n",
      " SCORE=0.969285934852\n",
      "Checking the ave of lightGBM_2\n",
      "1 0.975135394554 2 0.974951412095 3 0.974972015521 4 0.975054755777 5 0.975092386386 6 0.975171481588 7 0.975018919983 8 0.975187164684 9 0.97495807379 \n",
      " SCORE=0.976403856422\n",
      "Checking the ave of lightGBM_1\n",
      "1 0.974650009511 2 0.974606182413 3 0.974626104169 4 0.974870854694"
     ]
    }
   ],
   "source": [
    "output_dir = '../exponential_ave'\n",
    "print len(target)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "for m in models:\n",
    "    print \"Checking the ave of \" + m\n",
    "    ans = np.zeros(n)\n",
    "    testp = np.zeros(n_test)\n",
    "    for i in range(1, 10):\n",
    "        print i,\n",
    "        df = pd.read_csv('../output/{0}/fold_{1}/oof_pred.csv'.format(m, i))\n",
    "        df.pred = df.pred.apply(upper)\n",
    "        df.pred = df.pred.apply(lower)\n",
    "        df.pred = df.pred.apply(rev)\n",
    "        tmp = np.array(df.pred.tolist())\n",
    "        print roc_auc_score(target, sigmoid(tmp)),\n",
    "        ans += 1./9. * tmp\n",
    "        df = pd.read_csv('../output/{0}/fold_{1}/test_pred.csv'.format(m, i))\n",
    "        df.pred = df.pred.apply(upper)\n",
    "        df.pred = df.pred.apply(lower)\n",
    "        df.pred = df.pred.apply(rev)\n",
    "        testp += 1./9. * np.array(df.pred.tolist())\n",
    "    ans = sigmoid(ans)\n",
    "    testp = sigmoid(testp)\n",
    "    score = roc_auc_score(target, ans)\n",
    "    print \"\\n SCORE=\" + str(score)\n",
    "    oof_df = pd.DataFrame({\n",
    "        'is_attributed': list(target),\n",
    "        'pred': list(ans)\n",
    "    })\n",
    "    oof_df = oof_df[['is_attributed', 'pred']]\n",
    "    oof_df.to_csv(output_dir + '/' + m + '_oof_{SCORE}.csv'.format(SCORE=str(score)), index=False)\n",
    "    test_df = pd.DataFrame({\n",
    "        'click_id': ids,\n",
    "        'is_attributed': testp\n",
    "    })\n",
    "    test_df['click_id'] = test_df['click_id'].astype(int)\n",
    "    test_df = test_df[['click_id', 'is_attributed']]\n",
    "    test_df.to_csv(output_dir + '/' + m + '_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gridSearch(vecs, reso=0.02):\n",
    "    assert len(vecs) == 9\n",
    "    coeff = np.zeros(9)\n",
    "    coeff[0] = 1.\n",
    "    score = roc_auc_score(target, np.dot(coeff, vecs))\n",
    "    for c1 in np.arange(0, 1., reso):\n",
    "        print c1,\n",
    "        for c2 in np.arange(0, 1.-c1, reso):\n",
    "            for c3 in np.arange(0, 1.-c1-c2, reso):\n",
    "                for c4 in np.arange(0, 1.-c1-c2-c3, reso):\n",
    "                    for c5 in np.arange(0, 1.-c1-c2-c3-c4, reso):\n",
    "                        for c6 in np.arange(0, 1.-c1-c2-c3-c4-c5, reso):\n",
    "                            for c7 in np.arange(0, 1.-c1-c2-c3-c4-c5-c6, reso):\n",
    "                                for c8 in np.arange(0, 1.-c1-c2-c3-c4-c5-c6-c7, reso):\n",
    "                                    c9 = 1.-c1-c2-c3-c4-c5-c6-c7-c8\n",
    "                                    tmp_coeff = np.array([c1, c2, c3, c4, c5, c6, c7, c8, c9])\n",
    "                                    tmp_score = roc_auc_score(target, np.dot(tmp_coeff, vecs))\n",
    "                                    if tmp_score > score:\n",
    "                                        coeff = tmp_coeff\n",
    "                                        score = tmp_score\n",
    "    return coeff, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
